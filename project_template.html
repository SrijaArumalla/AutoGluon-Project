<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>a37f402d0d7a45adbf08b20e5cd06dba</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template"
class="cell markdown" id="-x-k6eaBxIjG">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<section id="project-predict-bike-sharing-demand-with-autogluon"
class="cell markdown" id="DgWZyKdRxIjI">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete
for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code>
markers in the notebook. You are welcome to add more cells and code as
you see fit.</p>
<p>Once you have completed all the code implementations, please export
your notebook as a HTML file so the reviews can view your code. Make
sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation
is done. Please answer all questions and attach the necessary tables and
charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of
the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project
beyond the minimum requirements. The stand out suggestions are optional.
If you decide to pursue the "stand out suggestions", you can include the
code in this notebook and also discuss the results in the writeup
file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle" class="cell markdown"
id="u1IAHMaQxIjJ">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key"
class="cell markdown" id="NS2JG7ffxIjK">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each
student will have their own username and key.</p>
</section>
<div class="cell markdown" id="ycOOo2caxIjK">
<ol>
<li>Open account settings. <span class="image placeholder"
data-original-image-src="kaggle1.png"
data-original-image-title="">kaggle1.png</span> <span
class="image placeholder" data-original-image-src="kaggle2.png"
data-original-image-title="">kaggle2.png</span></li>
<li>Scroll down to API and click Create New API Token. <span
class="image placeholder" data-original-image-src="kaggle3.png"
data-original-image-title="">kaggle3.png</span> <span
class="image placeholder" data-original-image-src="kaggle4.png"
data-original-image-title="">kaggle4.png</span></li>
<li>Open up <code>kaggle.json</code> and use the username and key. <span
class="image placeholder" data-original-image-src="kaggle5.png"
data-original-image-title="">kaggle5.png</span></li>
</ol>
</div>
<section
id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library"
class="cell markdown" id="XD3nA0anxIjK">
<h2>Step 2: Download the Kaggle dataset using the kaggle python
library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template"
class="cell markdown" id="TJlTXmvixIjL">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown" id="lSHdZJryxIjL">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2
vCPU + 4 GiB)</li>
<li>Notebook should be using kernal:
<code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown" id="2L67rf-gxIjM">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="1"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="EGh5hN8ExIjM" data-outputId="4732f3ce-455f-4045-c5a3-887dbdadfb0a"
data-tags="[]">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)
Collecting setuptools
  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 42.7 MB/s eta 0:00:00
ent already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools 67.7.2
    Uninstalling setuptools-67.7.2:
      Successfully uninstalled setuptools-67.7.2
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
ipython 7.34.0 requires jedi&gt;=0.16, which is not installed.
Successfully installed setuptools-67.8.0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb3"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;_distutils_hack&quot;</span><span class="ot">,</span><span class="st">&quot;pkg_resources&quot;</span><span class="ot">,</span><span class="st">&quot;setuptools&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting mxnet&lt;2.0.0
  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 13.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 68.2 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: PyYAML&gt;=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)
Requirement already satisfied: pillow&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (8.4.0)
Requirement already satisfied: packaging&gt;=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)
Requirement already satisfied: tornado&gt;=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing_extensions&gt;=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (2.27.1)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet&lt;2.0.0)
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Building wheels for collected packages: bokeh
  Building wheel for bokeh (setup.py) ... e=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=01fd3a94e83f7bf7e885a2585e020eb6d7e3c6656c2c039b438b50a95e97b395
  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754
Successfully built bokeh
Installing collected packages: graphviz, mxnet, bokeh
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.20.1
    Uninstalling graphviz-0.20.1:
      Successfully uninstalled graphviz-0.20.1
  Attempting uninstall: bokeh
    Found existing installation: bokeh 2.4.3
    Uninstalling bokeh-2.4.3:
      Successfully uninstalled bokeh-2.4.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting autogluon
  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)
Collecting autogluon.core[all]==0.7.0 (from autogluon)
  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.3/218.3 kB 54.7 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.1/60.1 kB 199.8 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 292.2/292.2 kB 166.5 MB/s eta 0:00:00
ultimodal==0.7.0 (from autogluon)
  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 178.6 MB/s eta 0:00:00
eseries[all]==0.7.0 (from autogluon)
  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.7/108.7 kB 164.5 MB/s eta 0:00:00
ent already satisfied: numpy&lt;1.27,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.22.4)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Collecting networkx&lt;3.0,&gt;=2.3 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 185.7 MB/s eta 0:00:00
ent already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.65.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.27.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.7.1)
Collecting boto3&lt;2,&gt;=1.10 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading boto3-1.26.142-py3-none-any.whl (135 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 138.8 MB/s eta 0:00:00
mon==0.7.0 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 138.1 MB/s eta 0:00:00
ent already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Collecting ray[tune]&lt;2.3,&gt;=2.2 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 MB 108.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 260.8 MB/s eta 0:00:00
a&lt;4.18,&gt;=4.14 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 83.6 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 143.3 MB/s eta 0:00:00
etadata (setup.py) ...  autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 202.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 260.8 MB/s eta 0:00:00
m&lt;0.7.0,&gt;=0.6.12 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading timm-0.6.13-py3-none-any.whl (549 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 549.1/549.1 kB 296.0 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.5/887.5 MB 177.7 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 97.7 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading fairscale-0.4.13.tar.gz (266 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 288.5 MB/s eta 0:00:00
ents to build wheel ... etadata (pyproject.toml) ... ent already satisfied: scikit-image&lt;0.20.0,&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Collecting pytorch-lightning&lt;1.10.0,&gt;=1.9.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.5/829.5 kB 296.4 MB/s eta 0:00:00
ent already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Collecting torchmetrics&lt;0.9.0,&gt;=0.8.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 311.1 MB/s eta 0:00:00
ers&lt;4.27.0,&gt;=4.23.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 96.9 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)
Collecting omegaconf&lt;2.3.0,&gt;=2.1.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 257.4 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 347.5 MB/s eta 0:00:00
etric-learning&lt;2.0,&gt;=1.3.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 243.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.5/410.5 kB 309.8 MB/s eta 0:00:00
ent already satisfied: nltk&lt;4.0.0,&gt;=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.1)
Collecting openmim&lt;0.4.0,&gt;0.1.5 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.3/51.3 kB 205.7 MB/s eta 0:00:00
ent already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.2)
Collecting pytesseract&lt;0.3.11,&gt;=0.3.9 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)
Collecting catboost&lt;1.2,&gt;=1.0 (from autogluon.tabular[all]==0.7.0-&gt;autogluon)
  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.6/76.6 MB 113.5 MB/s eta 0:00:00
ent already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.5)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Collecting gluonts&lt;0.13,&gt;=0.12.0 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 275.7 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 209.1 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 155.7 MB/s eta 0:00:00
e&lt;0.16,&gt;=0.14 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 161.6 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 167.0 MB/s eta 0:00:00
darima&lt;1.9,&gt;=1.8.2 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 259.1 MB/s eta 0:00:00
ent already satisfied: psutil&lt;6,&gt;=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.5)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0)
Collecting botocore&lt;1.30.0,&gt;=1.29.142 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading botocore-1.29.142-py3-none-any.whl (10.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 132.5 MB/s eta 0:00:00
espath&lt;2.0.0,&gt;=0.7.1 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer&lt;0.7.0,&gt;=0.6.0 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 144.3 MB/s eta 0:00:00
ent already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Collecting datasets&gt;=2.0.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 191.3 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading dill-0.3.6-py3-none-any.whl (110 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 171.2 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.5/212.5 kB 200.5 MB/s eta 0:00:00
ultiprocess (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.3/134.3 kB 172.7 MB/s eta 0:00:00
ent already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.0)
Collecting huggingface-hub&gt;=0.7.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 160.4 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.2)
Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: gdown&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.6.6)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2022.10.31)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 162.5 MB/s eta 0:00:00
etadata (setup.py) ... a (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Collecting model-index (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.4)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.10)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.7.1)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Collecting lightning-utilities&gt;=0.6.0.post0 (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Collecting aiosignal (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting frozenlist (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 278.6 MB/s eta 0:00:00
 ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 72.3 MB/s eta 0:00:00
ent already satisfied: grpcio&gt;=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.54.0)
Collecting tensorboardX&gt;=1.9 (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 164.4 MB/s eta 0:00:00
ent already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Collecting deprecated&gt;=1.2.13 (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)
Requirement already satisfied: numba&gt;=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.56.4)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.0)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 242.1 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 167.7 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 212.6 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 167.1 MB/s eta 0:00:00
 torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 99.0 MB/s eta 0:00:00
ent already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Collecting aiohttp (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 343.4 MB/s eta 0:00:00
ent already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.11.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.3.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.39.1)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.9)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting distlib&lt;1,&gt;=0.3.6 (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.5/468.5 kB 301.2 MB/s eta 0:00:00
ent already satisfied: platformdirs&lt;4,&gt;=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting ordered-set (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.14.0)
Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 279.8 MB/s eta 0:00:00
eout&lt;5.0,&gt;=4.0.0a3 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 200.4 MB/s eta 0:00:00
ent already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval
  Building wheel for fairscale (pyproject.toml) ... e=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=2c85b1cb46a926b8dbea016c608fe0047410330e79b371a268a9c70ccb822da0
  Stored in directory: /tmp/pip-ephem-wheel-cache-giurkz8l/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3
  Building wheel for antlr4-python3-runtime (setup.py) ... e: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4a35d5caa8bb32ad0e95ef72c1ddf8ce915c9404143553caf0afa0520c6d8deb
  Stored in directory: /tmp/pip-ephem-wheel-cache-giurkz8l/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88
  Building wheel for seqeval (setup.py) ... e=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=1141c521ab65ba5d09a25658e4c83a549093d980d90c0127967e76c046f568e8
  Stored in directory: /tmp/pip-ephem-wheel-cache-giurkz8l/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built fairscale antlr4-python3-runtime seqeval
Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, responses, pytesseract, nvidia-cudnn-cu11, multiprocess, model-index, huggingface-hub, botocore, aiosignal, transformers, torch, seqeval, s3transfer, ray, openmim, gluonts, catboost, aiohttp, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, boto3, accelerate, timm, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon
  Attempting uninstall: Pillow
    Found existing installation: Pillow 8.4.0
    Uninstalling Pillow-8.4.0:
      Successfully uninstalled Pillow-8.4.0
  Attempting uninstall: networkx
    Found existing installation: networkx 3.1
    Uninstalling networkx-3.1:
      Successfully uninstalled networkx-3.1
  Attempting uninstall: jsonschema
    Found existing installation: jsonschema 4.3.3
    Uninstalling jsonschema-4.3.3:
      Successfully uninstalled jsonschema-4.3.3
  Attempting uninstall: torch
    Found existing installation: torch 2.0.1+cu118
    Uninstalling torch-2.0.1+cu118:
      Successfully uninstalled torch-2.0.1+cu118
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.15.2+cu118
    Uninstalling torchvision-0.15.2+cu118:
      Successfully uninstalled torchvision-0.15.2+cu118
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
Successfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.142 botocore-1.29.142 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.14 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.8 huggingface-hub-0.14.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.1 sentencepiece-0.1.99 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1 ujson-5.7.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;PIL&quot;</span><span class="ot">,</span><span class="st">&quot;pydevd_plugins&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown"
id="u5jbB2uVxIjO">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="2" id="QHVep3ywxIjO"
data-tags="[]">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" id="drsQl7-MxIjP"
data-tags="[]">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;srijaarumalla&quot;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;39b7ca4481c234adeab5216005e4e4d2&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown"
id="hAce3Y1txIjP">
<h3>Download and explore dataset</h3>
</section>
<section
id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms"
class="cell markdown" id="5dRSn9LRxIjP">
<h3>Go to the <a
href="https://www.kaggle.com/c/bike-sharing-demand">bike sharing demand
competition</a> and agree to the terms</h3>
<p><span class="image placeholder" data-original-image-src="kaggle6.png"
data-original-image-title="">kaggle6.png</span></p>
</section>
<div class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="7k3KCWfCxIjP" data-outputId="f12d15eb-6fe2-437a-abf5-3b7f6098fe4c"
data-tags="[]">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a .zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /content
  0% 0.00/189k [00:00&lt;?, ?B/s]
100% 189k/189k [00:00&lt;00:00, 53.8MB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="5" id="pLZ9UOgcxIjP"
data-tags="[]">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="fcRpiO3_xIjQ" data-outputId="ea9611f3-56ca-4199-c6e4-87d2105d36b6">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">&quot;train.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">

  <div id="df-07c602ab-6c73-4652-92ba-db6b8d73ada2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-07c602ab-6c73-4652-92ba-db6b8d73ada2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-07c602ab-6c73-4652-92ba-db6b8d73ada2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-07c602ab-6c73-4652-92ba-db6b8d73ada2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}"
id="Ww2qWpe-xIjQ" data-outputId="4901f650-416b-470d-8d6c-d1dd6a205d75">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple output of the train dataset to view some of the min/max/varition of the dataset features.</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="7">

  <div id="df-b0cc3ae8-6554-495a-a765-d6ee9a5146a7">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b0cc3ae8-6554-495a-a765-d6ee9a5146a7')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b0cc3ae8-6554-495a-a765-d6ee9a5146a7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b0cc3ae8-6554-495a-a765-d6ee9a5146a7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="8"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="V-pPsi2QxIjQ" data-outputId="4e2733fb-a3f7-4e2e-aa8b-5d836088e370">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&quot;test.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">

  <div id="df-af9572ec-810e-4147-882e-ddbf901adc25">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-af9572ec-810e-4147-882e-ddbf901adc25')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-af9572ec-810e-4147-882e-ddbf901adc25 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-af9572ec-810e-4147-882e-ddbf901adc25');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="jdAywGhPxIjQ" data-outputId="bbf7eb25-9509-4bb2-d0c6-db6eb5f07999">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">

  <div id="df-808b0805-9d58-4a81-8728-cdca0dce2cc6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-808b0805-9d58-4a81-8728-cdca0dce2cc6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-808b0805-9d58-4a81-8728-cdca0dce2cc6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-808b0805-9d58-4a81-8728-cdca0dce2cc6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction"
class="cell markdown" id="T3_U9d5fxIjR">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown" id="isZ6vLa2xIjR">
<p>Requirements:</p>
<ul>
<li>We are predicting <code>count</code>, so it is the label we are
setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as
they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use
for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the
best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pVUKUhvxxIjR" data-outputId="149aa3a5-8d4e-40a4-8e94-2d8e6cd2f4e5">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&quot;count&quot;</span>,problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>,eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}).fit(train_data<span class="op">=</span>train,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>time_limit<span class="op">=</span><span class="dv">600</span>, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230530_000458/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230530_000458/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10944.35 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.3s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.34s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.67s of the 599.65s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.09s	 = Training   runtime
	0.09s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.42s of the 599.4s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.08s	 = Training   runtime
	0.1s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.19s of the 599.17s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.346	 = Validation score   (-root_mean_squared_error)
	142.93s	 = Training   runtime
	32.67s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 246.24s of the 446.22s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9173	 = Validation score   (-root_mean_squared_error)
	66.18s	 = Training   runtime
	4.66s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 170.53s of the 370.51s of remaining time.
	-38.3061	 = Validation score   (-root_mean_squared_error)
	23.21s	 = Training   runtime
	1.04s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 144.82s of the 344.8s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-35.6883	 = Validation score   (-root_mean_squared_error)
	136.6s	 = Training   runtime
	0.46s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.66s of the 201.64s of remaining time.
	-38.3116	 = Validation score   (-root_mean_squared_error)
	17.6s	 = Training   runtime
	1.2s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 177.05s of remaining time.
	-32.27	 = Validation score   (-root_mean_squared_error)
	0.75s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 176.26s of the 176.24s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.2122	 = Validation score   (-root_mean_squared_error)
	49.01s	 = Training   runtime
	1.61s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 120.28s of the 120.26s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6311	 = Validation score   (-root_mean_squared_error)
	43.99s	 = Training   runtime
	0.58s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 71.22s of the 71.2s of remaining time.
	-31.7472	 = Validation score   (-root_mean_squared_error)
	52.98s	 = Training   runtime
	0.7s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 16.22s of the 16.2s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-32.7515	 = Validation score   (-root_mean_squared_error)
	49.19s	 = Training   runtime
	0.33s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -47.37s of remaining time.
	-30.4369	 = Validation score   (-root_mean_squared_error)
	0.28s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 647.7s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230530_000458/&quot;)
</code></pre>
</div>
</div>
<section
id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best"
class="cell markdown" id="ruflO2KHxIjS">
<h3>Review AutoGluon's training run with ranking of models that did the
best.</h3>
</section>
<div class="cell code" data-execution_count="41"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="69JX37qDxIjS" data-outputId="8f38f2b6-096d-4067-f361-90f5e2e6ea51">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.436946      43.453215  582.150099                0.000950           0.283973            3       True         13
1          LightGBM_BAG_L2  -30.631053      40.812226  430.689790                0.578804          43.994981            2       True         10
2        LightGBMXT_BAG_L2  -31.212164      41.844875  435.703045                1.611453          49.008236            2       True          9
3   RandomForestMSE_BAG_L2  -31.747166      40.932934  439.673500                0.699512          52.978691            2       True         11
4      WeightedEnsemble_L2  -32.269960      38.937961  369.747148                0.001615           0.745531            2       True          8
5          CatBoost_BAG_L2  -32.751464      40.562496  435.884218                0.329074          49.189409            2       True         12
6          LightGBM_BAG_L1  -33.917339       4.657982   66.179179                4.657982          66.179179            1       True          4
7        LightGBMXT_BAG_L1  -34.345997      32.674835  142.927883               32.674835         142.927883            1       True          3
8          CatBoost_BAG_L1  -35.688347       0.461470  136.602645                0.461470         136.602645            1       True          6
9   RandomForestMSE_BAG_L1  -38.306120       1.041523   23.212414                1.041523          23.212414            1       True          5
10    ExtraTreesMSE_BAG_L1  -38.311570       1.202910   17.599092                1.202910          17.599092            1       True          7
11   KNeighborsDist_BAG_L1  -84.125061       0.100535    0.079496                0.100535           0.079496            1       True          2
12   KNeighborsUnif_BAG_L1 -101.546199       0.094167    0.094100                0.094167           0.094100            1       True          1
Number of models trained: 13
Types of models trained:
{&#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_KNN&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="41">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.34599701170154,
  &#39;LightGBM_BAG_L1&#39;: -33.91733862651761,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.30612025079756,
  &#39;CatBoost_BAG_L1&#39;: -35.688347011217914,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -38.31157013220686,
  &#39;WeightedEnsemble_L2&#39;: -32.26996025761409,
  &#39;LightGBMXT_BAG_L2&#39;: -31.212164459897753,
  &#39;LightGBM_BAG_L2&#39;: -30.631052806081502,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.74716639039753,
  &#39;CatBoost_BAG_L2&#39;: -32.751464465258415,
  &#39;WeightedEnsemble_L3&#39;: -30.43694550535538},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_000458/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230530_000458/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_000458/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_000458/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_000458/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_000458/models/CatBoost_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230530_000458/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.09409976005554199,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.07949566841125488,
  &#39;LightGBMXT_BAG_L1&#39;: 142.92788290977478,
  &#39;LightGBM_BAG_L1&#39;: 66.17917919158936,
  &#39;RandomForestMSE_BAG_L1&#39;: 23.212413787841797,
  &#39;CatBoost_BAG_L1&#39;: 136.60264539718628,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 17.59909152984619,
  &#39;WeightedEnsemble_L2&#39;: 0.7455310821533203,
  &#39;LightGBMXT_BAG_L2&#39;: 49.00823640823364,
  &#39;LightGBM_BAG_L2&#39;: 43.99498128890991,
  &#39;RandomForestMSE_BAG_L2&#39;: 52.9786913394928,
  &#39;CatBoost_BAG_L2&#39;: 49.189409255981445,
  &#39;WeightedEnsemble_L3&#39;: 0.28397250175476074},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.09416651725769043,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.10053515434265137,
  &#39;LightGBMXT_BAG_L1&#39;: 32.674834966659546,
  &#39;LightGBM_BAG_L1&#39;: 4.657981872558594,
  &#39;RandomForestMSE_BAG_L1&#39;: 1.0415232181549072,
  &#39;CatBoost_BAG_L1&#39;: 0.4614701271057129,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 1.2029099464416504,
  &#39;WeightedEnsemble_L2&#39;: 0.001615285873413086,
  &#39;LightGBMXT_BAG_L2&#39;: 1.6114530563354492,
  &#39;LightGBM_BAG_L2&#39;: 0.5788044929504395,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.6995117664337158,
  &#39;CatBoost_BAG_L2&#39;: 0.3290739059448242,
  &#39;WeightedEnsemble_L3&#39;: 0.000949859619140625},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.436946      43.453215  582.150099   
 1          LightGBM_BAG_L2  -30.631053      40.812226  430.689790   
 2        LightGBMXT_BAG_L2  -31.212164      41.844875  435.703045   
 3   RandomForestMSE_BAG_L2  -31.747166      40.932934  439.673500   
 4      WeightedEnsemble_L2  -32.269960      38.937961  369.747148   
 5          CatBoost_BAG_L2  -32.751464      40.562496  435.884218   
 6          LightGBM_BAG_L1  -33.917339       4.657982   66.179179   
 7        LightGBMXT_BAG_L1  -34.345997      32.674835  142.927883   
 8          CatBoost_BAG_L1  -35.688347       0.461470  136.602645   
 9   RandomForestMSE_BAG_L1  -38.306120       1.041523   23.212414   
 10    ExtraTreesMSE_BAG_L1  -38.311570       1.202910   17.599092   
 11   KNeighborsDist_BAG_L1  -84.125061       0.100535    0.079496   
 12   KNeighborsUnif_BAG_L1 -101.546199       0.094167    0.094100   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000950           0.283973            3       True   
 1                 0.578804          43.994981            2       True   
 2                 1.611453          49.008236            2       True   
 3                 0.699512          52.978691            2       True   
 4                 0.001615           0.745531            2       True   
 5                 0.329074          49.189409            2       True   
 6                 4.657982          66.179179            1       True   
 7                32.674835         142.927883            1       True   
 8                 0.461470         136.602645            1       True   
 9                 1.041523          23.212414            1       True   
 10                1.202910          17.599092            1       True   
 11                0.100535           0.079496            1       True   
 12                0.094167           0.094100            1       True   
 
     fit_order  
 0          13  
 1          10  
 2           9  
 3          11  
 4           8  
 5          12  
 6           4  
 7           3  
 8           6  
 9           5  
 10          7  
 11          2  
 12          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="42"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:457}"
id="SjIsKvAKAglF" data-outputId="953ebdad-a61d-4499-fd15-98a29ce04a87">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>lb_df <span class="op">=</span> pd.DataFrame(predictor.leaderboard(silent<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>lb_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="42">

  <div id="df-d5aa0c51-ce02-4600-ab4d-7592d6c20745">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>score_val</th>
      <th>pred_time_val</th>
      <th>fit_time</th>
      <th>pred_time_val_marginal</th>
      <th>fit_time_marginal</th>
      <th>stack_level</th>
      <th>can_infer</th>
      <th>fit_order</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>WeightedEnsemble_L3</td>
      <td>-30.436946</td>
      <td>43.453215</td>
      <td>582.150099</td>
      <td>0.000950</td>
      <td>0.283973</td>
      <td>3</td>
      <td>True</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>LightGBM_BAG_L2</td>
      <td>-30.631053</td>
      <td>40.812226</td>
      <td>430.689790</td>
      <td>0.578804</td>
      <td>43.994981</td>
      <td>2</td>
      <td>True</td>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LightGBMXT_BAG_L2</td>
      <td>-31.212164</td>
      <td>41.844875</td>
      <td>435.703045</td>
      <td>1.611453</td>
      <td>49.008236</td>
      <td>2</td>
      <td>True</td>
      <td>9</td>
    </tr>
    <tr>
      <th>3</th>
      <td>RandomForestMSE_BAG_L2</td>
      <td>-31.747166</td>
      <td>40.932934</td>
      <td>439.673500</td>
      <td>0.699512</td>
      <td>52.978691</td>
      <td>2</td>
      <td>True</td>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>WeightedEnsemble_L2</td>
      <td>-32.269960</td>
      <td>38.937961</td>
      <td>369.747148</td>
      <td>0.001615</td>
      <td>0.745531</td>
      <td>2</td>
      <td>True</td>
      <td>8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>CatBoost_BAG_L2</td>
      <td>-32.751464</td>
      <td>40.562496</td>
      <td>435.884218</td>
      <td>0.329074</td>
      <td>49.189409</td>
      <td>2</td>
      <td>True</td>
      <td>12</td>
    </tr>
    <tr>
      <th>6</th>
      <td>LightGBM_BAG_L1</td>
      <td>-33.917339</td>
      <td>4.657982</td>
      <td>66.179179</td>
      <td>4.657982</td>
      <td>66.179179</td>
      <td>1</td>
      <td>True</td>
      <td>4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>LightGBMXT_BAG_L1</td>
      <td>-34.345997</td>
      <td>32.674835</td>
      <td>142.927883</td>
      <td>32.674835</td>
      <td>142.927883</td>
      <td>1</td>
      <td>True</td>
      <td>3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>CatBoost_BAG_L1</td>
      <td>-35.688347</td>
      <td>0.461470</td>
      <td>136.602645</td>
      <td>0.461470</td>
      <td>136.602645</td>
      <td>1</td>
      <td>True</td>
      <td>6</td>
    </tr>
    <tr>
      <th>9</th>
      <td>RandomForestMSE_BAG_L1</td>
      <td>-38.306120</td>
      <td>1.041523</td>
      <td>23.212414</td>
      <td>1.041523</td>
      <td>23.212414</td>
      <td>1</td>
      <td>True</td>
      <td>5</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ExtraTreesMSE_BAG_L1</td>
      <td>-38.311570</td>
      <td>1.202910</td>
      <td>17.599092</td>
      <td>1.202910</td>
      <td>17.599092</td>
      <td>1</td>
      <td>True</td>
      <td>7</td>
    </tr>
    <tr>
      <th>11</th>
      <td>KNeighborsDist_BAG_L1</td>
      <td>-84.125061</td>
      <td>0.100535</td>
      <td>0.079496</td>
      <td>0.100535</td>
      <td>0.079496</td>
      <td>1</td>
      <td>True</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12</th>
      <td>KNeighborsUnif_BAG_L1</td>
      <td>-101.546199</td>
      <td>0.094167</td>
      <td>0.094100</td>
      <td>0.094167</td>
      <td>0.094100</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d5aa0c51-ce02-4600-ab4d-7592d6c20745')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d5aa0c51-ce02-4600-ab4d-7592d6c20745 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d5aa0c51-ce02-4600-ab4d-7592d6c20745');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="create-predictions-from-test-dataset" class="cell markdown"
id="cKcSHSPoxIjS">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="LegkVsE2xIjS" data-outputId="2c06f67b-ac34-4fa9-f98c-edde550efc60">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor.predict(test)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="43">
<pre><code>0    15.536628
1    10.848231
2     9.790624
3     8.638122
4     7.810686
Name: count, dtype: float32</code></pre>
</div>
</div>
<section
id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0"
class="cell markdown" id="hnW6q4YQxIjS">
<h4>NOTE: Kaggle will reject the submission if we don't set everything
to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="rxciosp7xIjS" data-outputId="18dcf813-82db-4fc1-de38-f17a426c1ee7">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="44">
<pre><code>count    6493.000000
mean      164.493729
std       146.950348
min         3.506394
25%        49.039925
50%       125.602325
75%       234.003998
max       817.501465
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="45"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="S0JxyOVGxIjT" data-outputId="2dd753d5-4a09-4b67-9b2b-9fddf251bfef">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions<span class="op">&lt;</span><span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="45">
<pre><code>Series([], Name: count, dtype: float32)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="46" id="Qdvl0Oh_xIjT">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions<span class="op">&lt;</span><span class="dv">0</span>]<span class="op">=</span><span class="dv">0</span></span></code></pre></div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit"
class="cell markdown" id="pCw7B708xIjT">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="47" id="Huj3jT9hxIjT">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="48"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="580P0S5OxIjT" data-outputId="62443732-cd27-42e3-bef7-5f4a59327b5e">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;first raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:00&lt;00:00, 316kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section
id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions"
class="cell markdown" id="ccXcw96WxIjT">
<h4>View submission via the command line or in the web browser under the
competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="YpU4P8vqxIjT" data-outputId="fdcf8c0d-1b44-4ffb-c0c2-4934855b24d2">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission.csv               2023-05-30 00:19:56  first raw submission               complete  0.60933      0.60933       
submission_new_hpo.csv       2023-05-30 00:03:11  new features with hyperparameters  complete  0.73541      0.73541       
submission_new_features.csv  2023-05-30 00:02:49  new features                       complete  0.61815      0.61815       
submission.csv               2023-05-30 00:02:21  first raw submission               complete  1.80528      1.80528       
</code></pre>
</div>
</div>
<section id="initial-score-of-180528" class="cell markdown"
id="e2gYa9SwxIjU">
<h4>Initial score of 1.80528</h4>
</section>
<section
id="step-4-exploratory-data-analysis-and-creating-an-additional-feature"
class="cell markdown" id="jQjw73-TxIjY">
<h2>Step 4: Exploratory Data Analysis and Creating an additional
feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to
separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="51"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="8XLLC63rxIjY" data-outputId="b00e5e54-3956-4f79-b915-c5b2ebdb93b4">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">15</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="51">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;year&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;month&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;day&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;hour&#39;}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]],
      dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_cd02855980534094afba8af339ded442/04857c1ca9d59f449883ad9a1a87c82913d0b038.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="52" id="68k0HyYxxIjZ">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.hour</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.hour</span></code></pre></div>
</div>
<section
id="make-category-types-for-these-so-models-know-they-are-not-just-numbers"
class="cell markdown" id="aP_NF81rxIjZ">
<h2>Make category types for these so models know they are not just
numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int
representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in
AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="53" id="_j7qX9O4xIjZ">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="54"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="cm7l1FptxIjZ" data-outputId="bf411ac8-a1b6-4b5c-9989-26a92e2bebbb">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="54">

  <div id="df-b8eebcd2-d2ef-4a43-b453-2c69d80dc42d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b8eebcd2-d2ef-4a43-b453-2c69d80dc42d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b8eebcd2-d2ef-4a43-b453-2c69d80dc42d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b8eebcd2-d2ef-4a43-b453-2c69d80dc42d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="55"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="T_QTa1n1xIjZ" data-outputId="f09269f4-f23e-4cf0-b853-b9b218dcf074">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="55">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;year&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;month&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;day&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;hour&#39;}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]],
      dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_cd02855980534094afba8af339ded442/cf202ef1a8209e0513e4def9643f73289f10c9e6.png" /></p>
</div>
</div>
<section
id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features"
class="cell markdown" id="y9netEVlxIja">
<h2>Step 5: Rerun the model with the same settings as before, just with
more features</h2>
</section>
<div class="cell code" data-execution_count="56"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PP9YOpURxIja" data-outputId="8837508d-eea4-480a-80a0-ce3e300e70a9">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>predictor_n_features <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&quot;count&quot;</span>,problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>, eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>,learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>[<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}).fit(train_data<span class="op">=</span>train, time_limit<span class="op">=</span><span class="dv">600</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230530_002118/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230530_002118/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10822.22 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.6s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.63s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.47s of the 599.36s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.34s of the 599.22s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.21s of the 599.09s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.346	 = Validation score   (-root_mean_squared_error)
	150.77s	 = Training   runtime
	35.89s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 240.8s of the 440.68s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9173	 = Validation score   (-root_mean_squared_error)
	64.75s	 = Training   runtime
	4.84s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 166.33s of the 366.21s of remaining time.
	-38.3061	 = Validation score   (-root_mean_squared_error)
	23.15s	 = Training   runtime
	0.98s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 140.81s of the 340.7s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-35.7185	 = Validation score   (-root_mean_squared_error)
	138.62s	 = Training   runtime
	0.41s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 194.81s of remaining time.
	-32.2709	 = Validation score   (-root_mean_squared_error)
	0.6s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 194.16s of the 194.13s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.2162	 = Validation score   (-root_mean_squared_error)
	48.22s	 = Training   runtime
	1.59s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 137.89s of the 137.88s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.5485	 = Validation score   (-root_mean_squared_error)
	46.37s	 = Training   runtime
	0.68s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 86.73s of the 86.71s of remaining time.
	-31.6938	 = Validation score   (-root_mean_squared_error)
	49.88s	 = Training   runtime
	0.84s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 35.04s of the 35.02s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.3115	 = Validation score   (-root_mean_squared_error)
	49.16s	 = Training   runtime
	0.37s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -20.86s of remaining time.
	-30.3323	 = Validation score   (-root_mean_squared_error)
	0.46s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 621.37s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230530_002118/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="57"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="AKciAU53xIja" data-outputId="e69be1ba-e528-4a46-c4ff-0ee0fc69bbda">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>predictor_n_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.332326      45.687290  571.443084                0.001268           0.456734            3       True         12
1          LightGBM_BAG_L2  -30.548540      42.884660  423.739585                0.677528          46.367375            2       True          9
2        LightGBMXT_BAG_L2  -31.216177      43.798992  425.587352                1.591860          48.215141            2       True          8
3          CatBoost_BAG_L2  -31.311467      42.576734  426.528601                0.369602          49.156390            2       True         11
4   RandomForestMSE_BAG_L2  -31.693799      43.047033  427.247444                0.839900          49.875234            2       True         10
5      WeightedEnsemble_L2  -32.270916      42.160896  377.929235                0.001694           0.600991            2       True          7
6          LightGBM_BAG_L1  -33.917339       4.838211   64.753031                4.838211          64.753031            1       True          4
7        LightGBMXT_BAG_L1  -34.345997      35.885840  150.767855               35.885840         150.767855            1       True          3
8          CatBoost_BAG_L1  -35.718471       0.405315  138.615457                0.405315         138.615457            1       True          6
9   RandomForestMSE_BAG_L1  -38.306120       0.980292   23.147839                0.980292          23.147839            1       True          5
10   KNeighborsDist_BAG_L1  -84.125061       0.049544    0.044061                0.049544           0.044061            1       True          2
11   KNeighborsUnif_BAG_L1 -101.546199       0.047931    0.043967                0.047931           0.043967            1       True          1
Number of models trained: 12
Types of models trained:
{&#39;StackerEnsembleModel_CatBoost&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_KNN&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="57">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.34599701170154,
  &#39;LightGBM_BAG_L1&#39;: -33.91733862651761,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.30612025079756,
  &#39;CatBoost_BAG_L1&#39;: -35.71847128567597,
  &#39;WeightedEnsemble_L2&#39;: -32.270915975386856,
  &#39;LightGBMXT_BAG_L2&#39;: -31.216177252360367,
  &#39;LightGBM_BAG_L2&#39;: -30.548539622311452,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.69379934777418,
  &#39;CatBoost_BAG_L2&#39;: -31.311467353456116,
  &#39;WeightedEnsemble_L3&#39;: -30.332325628143845},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230530_002118/models/CatBoost_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230530_002118/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_002118/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_002118/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_002118/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230530_002118/models/CatBoost_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230530_002118/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04396700859069824,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.04406094551086426,
  &#39;LightGBMXT_BAG_L1&#39;: 150.7678554058075,
  &#39;LightGBM_BAG_L1&#39;: 64.75303077697754,
  &#39;RandomForestMSE_BAG_L1&#39;: 23.147839307785034,
  &#39;CatBoost_BAG_L1&#39;: 138.61545705795288,
  &#39;WeightedEnsemble_L2&#39;: 0.6009910106658936,
  &#39;LightGBMXT_BAG_L2&#39;: 48.21514105796814,
  &#39;LightGBM_BAG_L2&#39;: 46.367374658584595,
  &#39;RandomForestMSE_BAG_L2&#39;: 49.87523365020752,
  &#39;CatBoost_BAG_L2&#39;: 49.15639042854309,
  &#39;WeightedEnsemble_L3&#39;: 0.45673418045043945},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04793071746826172,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.04954361915588379,
  &#39;LightGBMXT_BAG_L1&#39;: 35.88584017753601,
  &#39;LightGBM_BAG_L1&#39;: 4.838211297988892,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.9802918434143066,
  &#39;CatBoost_BAG_L1&#39;: 0.40531468391418457,
  &#39;WeightedEnsemble_L2&#39;: 0.0016942024230957031,
  &#39;LightGBMXT_BAG_L2&#39;: 1.5918595790863037,
  &#39;LightGBM_BAG_L2&#39;: 0.6775281429290771,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.8399004936218262,
  &#39;CatBoost_BAG_L2&#39;: 0.3696019649505615,
  &#39;WeightedEnsemble_L3&#39;: 0.0012676715850830078},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.332326      45.687290  571.443084   
 1          LightGBM_BAG_L2  -30.548540      42.884660  423.739585   
 2        LightGBMXT_BAG_L2  -31.216177      43.798992  425.587352   
 3          CatBoost_BAG_L2  -31.311467      42.576734  426.528601   
 4   RandomForestMSE_BAG_L2  -31.693799      43.047033  427.247444   
 5      WeightedEnsemble_L2  -32.270916      42.160896  377.929235   
 6          LightGBM_BAG_L1  -33.917339       4.838211   64.753031   
 7        LightGBMXT_BAG_L1  -34.345997      35.885840  150.767855   
 8          CatBoost_BAG_L1  -35.718471       0.405315  138.615457   
 9   RandomForestMSE_BAG_L1  -38.306120       0.980292   23.147839   
 10   KNeighborsDist_BAG_L1  -84.125061       0.049544    0.044061   
 11   KNeighborsUnif_BAG_L1 -101.546199       0.047931    0.043967   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.001268           0.456734            3       True   
 1                 0.677528          46.367375            2       True   
 2                 1.591860          48.215141            2       True   
 3                 0.369602          49.156390            2       True   
 4                 0.839900          49.875234            2       True   
 5                 0.001694           0.600991            2       True   
 6                 4.838211          64.753031            1       True   
 7                35.885840         150.767855            1       True   
 8                 0.405315         138.615457            1       True   
 9                 0.980292          23.147839            1       True   
 10                0.049544           0.044061            1       True   
 11                0.047931           0.043967            1       True   
 
     fit_order  
 0          12  
 1           9  
 2           8  
 3          11  
 4          10  
 5           7  
 6           4  
 7           3  
 8           6  
 9           5  
 10          2  
 11          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="58"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:425}"
id="aTWHcqM-CDAK" data-outputId="ba89ad54-e613-4c3c-d410-eaf3a18bf714">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>lb_nf_df <span class="op">=</span> pd.DataFrame(predictor_n_features.leaderboard(silent<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>lb_nf_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="58">

  <div id="df-a8bf5ebe-52ba-42b2-b92d-d77fa5798143">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>score_val</th>
      <th>pred_time_val</th>
      <th>fit_time</th>
      <th>pred_time_val_marginal</th>
      <th>fit_time_marginal</th>
      <th>stack_level</th>
      <th>can_infer</th>
      <th>fit_order</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>WeightedEnsemble_L3</td>
      <td>-30.332326</td>
      <td>45.687290</td>
      <td>571.443084</td>
      <td>0.001268</td>
      <td>0.456734</td>
      <td>3</td>
      <td>True</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>LightGBM_BAG_L2</td>
      <td>-30.548540</td>
      <td>42.884660</td>
      <td>423.739585</td>
      <td>0.677528</td>
      <td>46.367375</td>
      <td>2</td>
      <td>True</td>
      <td>9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LightGBMXT_BAG_L2</td>
      <td>-31.216177</td>
      <td>43.798992</td>
      <td>425.587352</td>
      <td>1.591860</td>
      <td>48.215141</td>
      <td>2</td>
      <td>True</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CatBoost_BAG_L2</td>
      <td>-31.311467</td>
      <td>42.576734</td>
      <td>426.528601</td>
      <td>0.369602</td>
      <td>49.156390</td>
      <td>2</td>
      <td>True</td>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>RandomForestMSE_BAG_L2</td>
      <td>-31.693799</td>
      <td>43.047033</td>
      <td>427.247444</td>
      <td>0.839900</td>
      <td>49.875234</td>
      <td>2</td>
      <td>True</td>
      <td>10</td>
    </tr>
    <tr>
      <th>5</th>
      <td>WeightedEnsemble_L2</td>
      <td>-32.270916</td>
      <td>42.160896</td>
      <td>377.929235</td>
      <td>0.001694</td>
      <td>0.600991</td>
      <td>2</td>
      <td>True</td>
      <td>7</td>
    </tr>
    <tr>
      <th>6</th>
      <td>LightGBM_BAG_L1</td>
      <td>-33.917339</td>
      <td>4.838211</td>
      <td>64.753031</td>
      <td>4.838211</td>
      <td>64.753031</td>
      <td>1</td>
      <td>True</td>
      <td>4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>LightGBMXT_BAG_L1</td>
      <td>-34.345997</td>
      <td>35.885840</td>
      <td>150.767855</td>
      <td>35.885840</td>
      <td>150.767855</td>
      <td>1</td>
      <td>True</td>
      <td>3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>CatBoost_BAG_L1</td>
      <td>-35.718471</td>
      <td>0.405315</td>
      <td>138.615457</td>
      <td>0.405315</td>
      <td>138.615457</td>
      <td>1</td>
      <td>True</td>
      <td>6</td>
    </tr>
    <tr>
      <th>9</th>
      <td>RandomForestMSE_BAG_L1</td>
      <td>-38.306120</td>
      <td>0.980292</td>
      <td>23.147839</td>
      <td>0.980292</td>
      <td>23.147839</td>
      <td>1</td>
      <td>True</td>
      <td>5</td>
    </tr>
    <tr>
      <th>10</th>
      <td>KNeighborsDist_BAG_L1</td>
      <td>-84.125061</td>
      <td>0.049544</td>
      <td>0.044061</td>
      <td>0.049544</td>
      <td>0.044061</td>
      <td>1</td>
      <td>True</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>KNeighborsUnif_BAG_L1</td>
      <td>-101.546199</td>
      <td>0.047931</td>
      <td>0.043967</td>
      <td>0.047931</td>
      <td>0.043967</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a8bf5ebe-52ba-42b2-b92d-d77fa5798143')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a8bf5ebe-52ba-42b2-b92d-d77fa5798143 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a8bf5ebe-52ba-42b2-b92d-d77fa5798143');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="64" id="wn6-4F27xIjb">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>n_predictions <span class="op">=</span> predictor_n_features.predict(test)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>n_predictions[n_predictions<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="65" id="re6Je2yZxIjb">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> n_predictions</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="66"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="mRk-PA0FxIjb" data-outputId="3c61e96d-9cfb-40fe-fb18-b563d5fb561b">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:00&lt;00:00, 366kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="69"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lhrqa3MVxIjb" data-outputId="2ac4cf9b-9cf8-424d-b08f-8a530d2c9cf8">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_features.csv  2023-05-30 00:35:57  new features                       complete  0.62648      0.62648       
submission_new_features.csv  2023-05-30 00:33:34  new features                       complete  0.62648      0.62648       
submission.csv               2023-05-30 00:19:56  first raw submission               complete  0.60933      0.60933       
submission_new_hpo.csv       2023-05-30 00:03:11  new features with hyperparameters  complete  0.73541      0.73541       
</code></pre>
</div>
</div>
<section id="new-score-of-061815" class="cell markdown"
id="m-653h9oxIjc">
<h4>New Score of 0.61815</h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown"
id="OX43UdGExIjc">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the
individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon.
Those need the <code>hyperparameter</code> and
<code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="70"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;75462435a19940929db7dc992c7f25ab&quot;,&quot;ed22a0d8aad04cf0a40bf84960bd9cd2&quot;,&quot;b5b86ba19354430cb809c6f762b662e1&quot;,&quot;9f22ef627c274c5ead1ba5bdd4a22a3c&quot;,&quot;901c0a792fa04df29fc1fff6a26552eb&quot;,&quot;ebbe705491b3428bb8febadb35c28dc1&quot;,&quot;a94e3d2aea99404b843955c09598950e&quot;,&quot;c874d40997fd4e3fb7676614c32d9374&quot;,&quot;527a425ed0bd423ea8671347d105a685&quot;,&quot;d14af6deafd34aecaa1e0ad1bead4213&quot;,&quot;4fb00e6ec85e4533ab8c1d88644d5115&quot;,&quot;193110181ab648ac867fb0cd96f9deb2&quot;,&quot;a0e8cfe19b3f47638b52d7eaa80d21ee&quot;,&quot;1f896963264a414f89c029838157a3c9&quot;,&quot;9aacbedbc77043678f8138e788198068&quot;,&quot;c992930a1f844b349d552a5a3026c129&quot;,&quot;e7e76b76e8024e7faa59466be705ee9b&quot;,&quot;f134c636dc304b95bc64a8a8ba1c64d0&quot;,&quot;82fab622a439415d9a295a8fa44b3126&quot;,&quot;fb23d0fd18ac44238c4499b18408481e&quot;,&quot;81ca30460c854940b7416a72f25cc435&quot;,&quot;2cf60248e3a948618bb605c3e941176d&quot;,&quot;30f89e2121a349a69f80d1eaf7ee6ee9&quot;,&quot;9f5d3ecc59af4aec807d79a67aa97ef2&quot;,&quot;8fb7e30ed9764eaaa4232a6052231912&quot;,&quot;4f42820e1ac0487097a99320850a56ca&quot;,&quot;1bebfa3e8b0d4dc0af7f489c43d74f2e&quot;,&quot;99a804348f6b40a6a01186151f713915&quot;,&quot;38a7c696a68f4236925098add3835247&quot;,&quot;2311bb912a2e4ce795cc44d3bc041d73&quot;,&quot;69efcd272edf484aa4977d8b7052284a&quot;,&quot;de1eb05e109f4ac987c37582a19e0dd7&quot;,&quot;521934bb191d4545976bf933e3a8d2ee&quot;,&quot;bbba83ee05fa40d4b79602f3c3c5202b&quot;,&quot;bf85bbe7e07c432d92f10d1f49b9e4eb&quot;,&quot;06be2246beb946198d97338e080fe092&quot;,&quot;b7eb3a4d45bf4e5ba805cff425503f62&quot;,&quot;1b71939faf3c402daf5c29b40e5d02e1&quot;,&quot;3d574383ed83475ca8f0784360658c68&quot;,&quot;e03ac33d9f474afebd4e7099b7993c1a&quot;,&quot;f3046042c8d648a9b100f5494b62feba&quot;,&quot;950594e2b3c04390a6d009d906fea344&quot;,&quot;275bad9a2ebe485ea5db8e232743852f&quot;,&quot;a9225d5727be4b16836b48b3b2f5f18a&quot;]}"
id="GeXaumJmxIjc" data-outputId="de2eb8dd-e70e-4097-8bf3-8ce1e9d02c7d">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.core <span class="im">as</span> ag</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>nn_options <span class="op">=</span> {<span class="st">&#39;num_epochs&#39;</span>: <span class="dv">10</span>, </span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;learning_rate&#39;</span>: ag.space.Real(<span class="fl">1e-4</span>, <span class="fl">1e-2</span>, default<span class="op">=</span><span class="fl">5e-4</span>, log<span class="op">=</span><span class="va">True</span>),  </span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;activation&#39;</span>: ag.space.Categorical(<span class="st">&#39;relu&#39;</span>, <span class="st">&#39;softrelu&#39;</span>, <span class="st">&#39;tanh&#39;</span>),  </span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;dropout_prob&#39;</span>: ag.space.Real(<span class="fl">0.0</span>, <span class="fl">0.5</span>, default<span class="op">=</span><span class="fl">0.1</span>)}</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>gbm_options <span class="op">=</span> [{<span class="st">&#39;extra_trees&#39;</span>: <span class="va">True</span>, </span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;num_boost_round&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">100</span>, upper<span class="op">=</span><span class="dv">500</span>, default<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;num_leaves&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">26</span>, upper<span class="op">=</span><span class="dv">66</span>, default<span class="op">=</span><span class="dv">36</span>)}]</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>hp <span class="op">=</span> {  <span class="st">&#39;GBM&#39;</span>: gbm_options,</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;NN&#39;</span>: nn_options, </span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>     }  </span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a>hp_tune_kwargs <span class="op">=</span> { </span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_trials&#39;</span>: <span class="dv">25</span>,</span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;searcher&#39;</span>: <span class="st">&#39;auto&#39;</span></span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a>predictor_hp <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&#39;count&#39;</span>, problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>, eval_metric<span class="op">=</span><span class="st">&#39;root_mean_squared_error&#39;</span>,</span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a>                                    learner_kwargs<span class="op">=</span>{<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}).fit(</span>
<span id="cb54-35"><a href="#cb54-35" aria-hidden="true" tabindex="-1"></a>                                                                         train_data<span class="op">=</span>train, </span>
<span id="cb54-36"><a href="#cb54-36" aria-hidden="true" tabindex="-1"></a>                                                                         time_limit<span class="op">=</span><span class="dv">600</span>,</span>
<span id="cb54-37"><a href="#cb54-37" aria-hidden="true" tabindex="-1"></a>                                                                         presets<span class="op">=</span><span class="st">&#39;best_quality&#39;</span>, </span>
<span id="cb54-38"><a href="#cb54-38" aria-hidden="true" tabindex="-1"></a>                                                                         hyperparameters<span class="op">=</span>hp, </span>
<span id="cb54-39"><a href="#cb54-39" aria-hidden="true" tabindex="-1"></a>                                                                         hyperparameter_tune_kwargs<span class="op">=</span>hp_tune_kwargs,</span>
<span id="cb54-40"><a href="#cb54-40" aria-hidden="true" tabindex="-1"></a>                                                                         refit_full<span class="op">=</span><span class="st">&#39;best&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230530_003711/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230530_003711/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10792.63 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.22s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 179.89s of the 599.77s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb56"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;75462435a19940929db7dc992c7f25ab&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L1/T1 ...
	-73.4652	 = Validation score   (-root_mean_squared_error)
	44.36s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-44.7051	 = Validation score   (-root_mean_squared_error)
	39.18s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T3 ...
	-45.8596	 = Validation score   (-root_mean_squared_error)
	46.31s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T4 ...
	-38.6351	 = Validation score   (-root_mean_squared_error)
	45.86s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 179.89s of the 423.82s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;193110181ab648ac867fb0cd96f9deb2&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=34278, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34278, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:40:20,373	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34381, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34381, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:40:34,296	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34543, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34543, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:40:46,238	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34656, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34656, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:00,392	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34758, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34758, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:02,465	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34857, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34857, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:14,210	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=34976, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=34976, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-30 00:41:20,719	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=35069, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35069, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:32,819	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35219, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35219, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:42,526	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35331, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35331, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:41:52,860	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35472, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35472, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:04,383	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35586, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35586, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:10,871	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35683, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35683, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:23,747	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35804, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35804, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:32,320	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=35936, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=35936, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:41,592	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=36042, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=36042, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:42:53,156	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=36160, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=36160, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Stopping HPO to satisfy time limit...
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 252.09s of remaining time.
	-38.5493	 = Validation score   (-root_mean_squared_error)
	0.55s	 = Training   runtime
	0.0s	 = Validation runtime
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 113.18s of the 251.47s of remaining time.
2023-05-30 00:43:00,394	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;30f89e2121a349a69f80d1eaf7ee6ee9&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L2/T1 ...
	-39.9822	 = Validation score   (-root_mean_squared_error)
	40.33s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-37.3104	 = Validation score   (-root_mean_squared_error)
	41.79s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 113.18s of the 169.16s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb62"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;bbba83ee05fa40d4b79602f3c3c5202b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=37107, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37107, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:44:33,017	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=37211, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37211, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:44:42,326	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=37318, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37318, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-30 00:44:53,759	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=37436, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37436, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:45:01,925	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=37569, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37569, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:45:18,117	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=37731, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37731, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:45:29,886	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=37869, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=37869, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:45:43,159	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=38035, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=38035, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-30 00:45:50,624	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=38128, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=38128, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-30 00:46:02,060	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=38243, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=38243, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Stopping HPO to satisfy time limit...
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 60.41s of remaining time.
2023-05-30 00:46:11,429	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	-37.3068	 = Validation score   (-root_mean_squared_error)
	0.31s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 539.95s ... Best model: &quot;WeightedEnsemble_L3&quot;
Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`
Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...
	Models trained in this way will have the suffix &quot;_FULL&quot; and have NaN validation score.
	This process is not bound by time_limit, but should take less time than the original `predictor.fit` call.
	To learn more, refer to the `.refit_full` method docstring which explains how &quot;_FULL&quot; models differ from normal models.
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1/T1_FULL ...
	1.19s	 = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1/T2_FULL ...
	1.18s	 = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1/T3_FULL ...
	1.31s	 = Training   runtime
Fitting 1 L1 models ...
Fitting model: LightGBM_BAG_L1/T4_FULL ...
	1.8s	 = Training   runtime
Fitting 1 L2 models ...
Fitting model: LightGBM_BAG_L2/T1_FULL ...
	1.38s	 = Training   runtime
Fitting 1 L2 models ...
Fitting model: LightGBM_BAG_L2/T2_FULL ...
	1.69s	 = Training   runtime
Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...
	0.31s	 = Training   runtime
Refit complete, total runtime = 12.54s
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230530_003711/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="71"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2B-RtC6ixIjd" data-outputId="17c8df13-97c0-40f6-c47f-bdb4735f514c">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>predictor_hp.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                       model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0        WeightedEnsemble_L3 -37.306846       0.003187  258.138810                0.001216           0.307896            3       True          8
1         LightGBM_BAG_L2/T2 -37.310395       0.001804  217.502011                0.000164          41.793158            2       True          7
2        WeightedEnsemble_L2 -38.549310       0.001788   85.591645                0.001437           0.549635            2       True          5
3         LightGBM_BAG_L1/T4 -38.635091       0.000170   45.862854                0.000170          45.862854            1       True          4
4         LightGBM_BAG_L2/T1 -39.982151       0.001808  216.037756                0.000168          40.328903            2       True          6
5         LightGBM_BAG_L1/T2 -44.705078       0.000181   39.179156                0.000181          39.179156            1       True          2
6         LightGBM_BAG_L1/T3 -45.859613       0.001121   46.311606                0.001121          46.311606            1       True          3
7         LightGBM_BAG_L1/T1 -73.465206       0.000168   44.355237                0.000168          44.355237            1       True          1
8   WeightedEnsemble_L3_FULL        NaN            NaN    8.867185                     NaN           0.307896            3       True         15
9    LightGBM_BAG_L2/T2_FULL        NaN            NaN    7.182878                     NaN           1.691982            2       True         14
10   LightGBM_BAG_L2/T1_FULL        NaN            NaN    6.867307                     NaN           1.376411            2       True         13
11   LightGBM_BAG_L1/T4_FULL        NaN            NaN    1.802732                     NaN           1.802732            1       True         12
12   LightGBM_BAG_L1/T3_FULL        NaN            NaN    1.314248                     NaN           1.314248            1       True         11
13   LightGBM_BAG_L1/T2_FULL        NaN            NaN    1.180058                     NaN           1.180058            1       True         10
14   LightGBM_BAG_L1/T1_FULL        NaN            NaN    1.193859                     NaN           1.193859            1       True          9
Number of models trained: 15
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="71">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3_FULL&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -73.46520573556604,
  &#39;LightGBM_BAG_L1/T2&#39;: -44.70507823444231,
  &#39;LightGBM_BAG_L1/T3&#39;: -45.859612694265245,
  &#39;LightGBM_BAG_L1/T4&#39;: -38.63509077248987,
  &#39;WeightedEnsemble_L2&#39;: -38.54931048937091,
  &#39;LightGBM_BAG_L2/T1&#39;: -39.98215138020563,
  &#39;LightGBM_BAG_L2/T2&#39;: -37.31039499337394,
  &#39;WeightedEnsemble_L3&#39;: -37.306845780730285,
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: None,
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: None,
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: None,
  &#39;WeightedEnsemble_L3_FULL&#39;: None},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T3/&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T4/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230530_003711/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230530_003711/models/WeightedEnsemble_L3/&#39;,
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T1_FULL/&#39;,
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T2_FULL/&#39;,
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T3_FULL/&#39;,
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L1/T4_FULL/&#39;,
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L2/T1_FULL/&#39;,
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: &#39;/content/AutogluonModels/ag-20230530_003711/models/LightGBM_BAG_L2/T2_FULL/&#39;,
  &#39;WeightedEnsemble_L3_FULL&#39;: &#39;AutogluonModels/ag-20230530_003711/models/WeightedEnsemble_L3_FULL/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 44.355236768722534,
  &#39;LightGBM_BAG_L1/T2&#39;: 39.179155588150024,
  &#39;LightGBM_BAG_L1/T3&#39;: 46.31160616874695,
  &#39;LightGBM_BAG_L1/T4&#39;: 45.86285400390625,
  &#39;WeightedEnsemble_L2&#39;: 0.5496354103088379,
  &#39;LightGBM_BAG_L2/T1&#39;: 40.32890343666077,
  &#39;LightGBM_BAG_L2/T2&#39;: 41.79315805435181,
  &#39;WeightedEnsemble_L3&#39;: 0.30789637565612793,
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: 1.1938586235046387,
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: 1.1800575256347656,
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: 1.3142480850219727,
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: 1.802731990814209,
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: 1.376410961151123,
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: 1.691981554031372,
  &#39;WeightedEnsemble_L3_FULL&#39;: 0.30789637565612793},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.00016832351684570312,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.00018072128295898438,
  &#39;LightGBM_BAG_L1/T3&#39;: 0.0011205673217773438,
  &#39;LightGBM_BAG_L1/T4&#39;: 0.0001704692840576172,
  &#39;WeightedEnsemble_L2&#39;: 0.0014367103576660156,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.00016760826110839844,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.00016355514526367188,
  &#39;WeightedEnsemble_L3&#39;: 0.0012159347534179688,
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: None,
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: None,
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: None,
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: None,
  &#39;WeightedEnsemble_L3_FULL&#39;: None},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T4&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T1_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T4_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2_FULL&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3_FULL&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                        model  score_val  pred_time_val    fit_time  \
 0        WeightedEnsemble_L3 -37.306846       0.003187  258.138810   
 1         LightGBM_BAG_L2/T2 -37.310395       0.001804  217.502011   
 2        WeightedEnsemble_L2 -38.549310       0.001788   85.591645   
 3         LightGBM_BAG_L1/T4 -38.635091       0.000170   45.862854   
 4         LightGBM_BAG_L2/T1 -39.982151       0.001808  216.037756   
 5         LightGBM_BAG_L1/T2 -44.705078       0.000181   39.179156   
 6         LightGBM_BAG_L1/T3 -45.859613       0.001121   46.311606   
 7         LightGBM_BAG_L1/T1 -73.465206       0.000168   44.355237   
 8   WeightedEnsemble_L3_FULL        NaN            NaN    8.867185   
 9    LightGBM_BAG_L2/T2_FULL        NaN            NaN    7.182878   
 10   LightGBM_BAG_L2/T1_FULL        NaN            NaN    6.867307   
 11   LightGBM_BAG_L1/T4_FULL        NaN            NaN    1.802732   
 12   LightGBM_BAG_L1/T3_FULL        NaN            NaN    1.314248   
 13   LightGBM_BAG_L1/T2_FULL        NaN            NaN    1.180058   
 14   LightGBM_BAG_L1/T1_FULL        NaN            NaN    1.193859   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.001216           0.307896            3       True   
 1                 0.000164          41.793158            2       True   
 2                 0.001437           0.549635            2       True   
 3                 0.000170          45.862854            1       True   
 4                 0.000168          40.328903            2       True   
 5                 0.000181          39.179156            1       True   
 6                 0.001121          46.311606            1       True   
 7                 0.000168          44.355237            1       True   
 8                      NaN           0.307896            3       True   
 9                      NaN           1.691982            2       True   
 10                     NaN           1.376411            2       True   
 11                     NaN           1.802732            1       True   
 12                     NaN           1.314248            1       True   
 13                     NaN           1.180058            1       True   
 14                     NaN           1.193859            1       True   
 
     fit_order  
 0           8  
 1           7  
 2           5  
 3           4  
 4           6  
 5           2  
 6           3  
 7           1  
 8          15  
 9          14  
 10         13  
 11         12  
 12         11  
 13         10  
 14          9  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="72"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:519}"
id="4LahKod3H6r7" data-outputId="5d321b3e-2b74-4213-e295-b36432f23974">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>lb_hp_df <span class="op">=</span> pd.DataFrame(predictor_hp.leaderboard(silent<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>lb_hp_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="72">

  <div id="df-6fed5531-ca7f-4d8a-8298-f60631f05bc4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>score_val</th>
      <th>pred_time_val</th>
      <th>fit_time</th>
      <th>pred_time_val_marginal</th>
      <th>fit_time_marginal</th>
      <th>stack_level</th>
      <th>can_infer</th>
      <th>fit_order</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>WeightedEnsemble_L3</td>
      <td>-37.306846</td>
      <td>0.003187</td>
      <td>258.138810</td>
      <td>0.001216</td>
      <td>0.307896</td>
      <td>3</td>
      <td>True</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>LightGBM_BAG_L2/T2</td>
      <td>-37.310395</td>
      <td>0.001804</td>
      <td>217.502011</td>
      <td>0.000164</td>
      <td>41.793158</td>
      <td>2</td>
      <td>True</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>WeightedEnsemble_L2</td>
      <td>-38.549310</td>
      <td>0.001788</td>
      <td>85.591645</td>
      <td>0.001437</td>
      <td>0.549635</td>
      <td>2</td>
      <td>True</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LightGBM_BAG_L1/T4</td>
      <td>-38.635091</td>
      <td>0.000170</td>
      <td>45.862854</td>
      <td>0.000170</td>
      <td>45.862854</td>
      <td>1</td>
      <td>True</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LightGBM_BAG_L2/T1</td>
      <td>-39.982151</td>
      <td>0.001808</td>
      <td>216.037756</td>
      <td>0.000168</td>
      <td>40.328903</td>
      <td>2</td>
      <td>True</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>LightGBM_BAG_L1/T2</td>
      <td>-44.705078</td>
      <td>0.000181</td>
      <td>39.179156</td>
      <td>0.000181</td>
      <td>39.179156</td>
      <td>1</td>
      <td>True</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>LightGBM_BAG_L1/T3</td>
      <td>-45.859613</td>
      <td>0.001121</td>
      <td>46.311606</td>
      <td>0.001121</td>
      <td>46.311606</td>
      <td>1</td>
      <td>True</td>
      <td>3</td>
    </tr>
    <tr>
      <th>7</th>
      <td>LightGBM_BAG_L1/T1</td>
      <td>-73.465206</td>
      <td>0.000168</td>
      <td>44.355237</td>
      <td>0.000168</td>
      <td>44.355237</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>WeightedEnsemble_L3_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.867185</td>
      <td>NaN</td>
      <td>0.307896</td>
      <td>3</td>
      <td>True</td>
      <td>15</td>
    </tr>
    <tr>
      <th>9</th>
      <td>LightGBM_BAG_L2/T2_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>7.182878</td>
      <td>NaN</td>
      <td>1.691982</td>
      <td>2</td>
      <td>True</td>
      <td>14</td>
    </tr>
    <tr>
      <th>10</th>
      <td>LightGBM_BAG_L2/T1_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.867307</td>
      <td>NaN</td>
      <td>1.376411</td>
      <td>2</td>
      <td>True</td>
      <td>13</td>
    </tr>
    <tr>
      <th>11</th>
      <td>LightGBM_BAG_L1/T4_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.802732</td>
      <td>NaN</td>
      <td>1.802732</td>
      <td>1</td>
      <td>True</td>
      <td>12</td>
    </tr>
    <tr>
      <th>12</th>
      <td>LightGBM_BAG_L1/T3_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.314248</td>
      <td>NaN</td>
      <td>1.314248</td>
      <td>1</td>
      <td>True</td>
      <td>11</td>
    </tr>
    <tr>
      <th>13</th>
      <td>LightGBM_BAG_L1/T2_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.180058</td>
      <td>NaN</td>
      <td>1.180058</td>
      <td>1</td>
      <td>True</td>
      <td>10</td>
    </tr>
    <tr>
      <th>14</th>
      <td>LightGBM_BAG_L1/T1_FULL</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.193859</td>
      <td>NaN</td>
      <td>1.193859</td>
      <td>1</td>
      <td>True</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6fed5531-ca7f-4d8a-8298-f60631f05bc4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6fed5531-ca7f-4d8a-8298-f60631f05bc4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6fed5531-ca7f-4d8a-8298-f60631f05bc4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="73" id="67b_msdPxIjd">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>new_predictions_hp <span class="op">=</span> predictor_hp.predict(test)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>new_predictions_hp[new_predictions_hp<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="74" id="H1DOBN2zxIjd">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> new_predictions_hp</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="75"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2JZrUYqMxIjd" data-outputId="27df42ac-c2f3-49d5-99e8-725e9a892ad1">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:00&lt;00:00, 500kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="78"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Hy5bceH3xIje" data-outputId="cab143c4-72df-43af-e630-af7065e7e207">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-05-30 00:50:02  new features with hyperparameters  complete  0.45792      0.45792       
submission_new_features.csv  2023-05-30 00:35:57  new features                       complete  0.62648      0.62648       
submission_new_features.csv  2023-05-30 00:33:34  new features                       complete  0.62648      0.62648       
submission.csv               2023-05-30 00:19:56  first raw submission               complete  0.60933      0.60933       
</code></pre>
</div>
</div>
<section id="new-score-of-045792" class="cell markdown"
id="2PwrKawvxIje">
<h4>New Score of 0.45792</h4>
</section>
<section id="step-7-write-a-report" class="cell markdown"
id="hXhdMeOexIje">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the
markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table
for report</h3>
</section>
<div class="cell code" data-execution_count="79"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="SCn3vCNnxIje" data-jupyter="{&quot;source_hidden&quot;:true}"
data-outputId="86367ce6-0928-457c-b0d5-738385768ba4">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">30.34946</span>, <span class="fl">30.332326</span>, <span class="fl">37.306846</span>]</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_cd02855980534094afba8af339ded442/f1608b9f82fa48f389cf1fdb13bcb2a75312b5ca.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="81"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="AkebURK4xIje" data-outputId="5755cf63-51fb-4355-d3b2-216518786641">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">0.60933</span>,<span class="fl">0.62648</span>, <span class="fl">0.45792</span>]</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_cd02855980534094afba8af339ded442/1b8ecab7542ac774de50f93226a77e061e22f590.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown"
id="Ri371uVhxIjf">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="82"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:170}"
id="-BXHgzQgxIjf" data-outputId="3db241af-b8bb-468a-bde4-e7c521447538">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;timelimit&quot;</span>: [<span class="st">&quot;time_limit = 600&quot;</span>, <span class="st">&quot;time_limit=600&quot;</span>, <span class="st">&quot;time_limit=600&quot;</span>],</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;presets&quot;</span>: [<span class="st">&quot;presets=&#39;best_quality&#39;&quot;</span>, <span class="st">&quot;presets=&#39;best_quality&#39;&quot;</span>, <span class="st">&quot;presets=&#39;best_quality&#39;&quot;</span>],</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hp-method&quot;</span>: [<span class="st">&quot;none&quot;</span>, <span class="st">&quot;problem_type = &#39;regression&#39;&quot;</span>, <span class="st">&quot;tabular autogluon&quot;</span>],</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">0.60933</span>,<span class="fl">0.62648</span>, <span class="fl">0.45792</span>]</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="82">

  <div id="df-2cdc3977-9516-417e-bb97-26789839ffb5">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>timelimit</th>
      <th>presets</th>
      <th>hp-method</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial</td>
      <td>time_limit = 600</td>
      <td>presets='best_quality'</td>
      <td>none</td>
      <td>0.60933</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features</td>
      <td>time_limit=600</td>
      <td>presets='best_quality'</td>
      <td>problem_type = 'regression'</td>
      <td>0.62648</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo</td>
      <td>time_limit=600</td>
      <td>presets='best_quality'</td>
      <td>tabular autogluon</td>
      <td>0.45792</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2cdc3977-9516-417e-bb97-26789839ffb5')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-2cdc3977-9516-417e-bb97-26789839ffb5 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-2cdc3977-9516-417e-bb97-26789839ffb5');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" id="BaO4MgdXNSHK">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
